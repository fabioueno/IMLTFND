{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "When we're building our Machine Learning model, we can specify some paremeters, called Hyper-Parameters. In a Logistic Regression this could be the degree of the function, while in a Decision Tree this would be the depth.\n",
    "\n",
    "<br>\n",
    "<img src='images/hyperparameters-regression.png' style='float: left' width='480px'>\n",
    "<img src='images/hyperparameters-tree.png' style='float: right' width='480px'>\n",
    "<div style='clear: both'></div>\n",
    "<br>\n",
    "\n",
    "What we do is try some values of hyper-parameters, train with the Training Data, test against the Cross-Validation Data, evaluate with some metric, say F1 Score, then choose the best and validate with the Testing Data. In practice, we don't manually test all the values, but use a Grid Search, which builds the table of hyper-parameters internally and outputs the best one.\n",
    "\n",
    "<br><img src='images/grid-search.png' width='720px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search in sklearn\n",
    "\n",
    "Grid Search in sklearn is very simple. We'll illustrate it with an example. Let's say we'd like to train a support vector machine, and we'd like to decide between the following parameters:\n",
    "\n",
    "* kernel: `poly` or `rbf`.\n",
    "* C: 0.1, 1, or 10.\n",
    "\n",
    "_(Note: These parameters can be used as a black box now, but we'll see them in detail in the **Supervised Learning Section** of the nanodegree.)_\n",
    "\n",
    "The steps are the following:\n",
    "\n",
    "**1. Import GridSearchCV**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "**2. Select the parameters:**\n",
    "\n",
    "Here we pick what are the parameters we want to choose from, and form a dictionary. In this dictionary, the keys will be the names of the parameters, and the values will be the lists of possible values for each parameter.\n",
    "\n",
    "```python\n",
    "parameters = {'kernel': ['poly', 'rbf'], 'C': [0.1, 1, 10]}\n",
    "```\n",
    "\n",
    "**3. Create a scorer.**\n",
    "\n",
    "We need to decide what metric we'll use to score each of the candidate models. In here, we'll use F1 Score.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "scorer = make_scorer(f1_score)\n",
    "```\n",
    "\n",
    "**4. Create a GridSearch Object with the parameters, and the scorer. Use this object to fit the data.**\n",
    "\n",
    "```python\n",
    "# Create the object.\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring = scorer)\n",
    "\n",
    "# Fit the data\n",
    "grid_fit = grid_obj.fit(X, y)\n",
    "```\n",
    "\n",
    "**5. Get the best estimator.**\n",
    "\n",
    "```python\n",
    "best_clf = grid_fit.best_estimator_\n",
    "```\n",
    "\n",
    "Now you can use this estimator `best_clf` to make the predictions.\n",
    "\n",
    "In the next page, you'll find a lab where you can use GridSearchCV to optimize a decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quizes\n",
    "\n",
    "01. [Grid Search](../../quizes/grid-search/grid-search.ipynb)\n",
    "02. [Diabetes](../../diabetes/diabetes.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
